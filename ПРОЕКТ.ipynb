{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "904e176b",
   "metadata": {},
   "source": [
    "### **ЗАГРУЗКА БИБЛИОТЕК*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc818e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# убираем предупреждения\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# парcинг\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "#  Регулярные выражения \n",
    "import re\n",
    "\n",
    "# визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# загрузка файлов с относительным путем\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from tkinter import filedialog\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e460d2",
   "metadata": {},
   "source": [
    "### **ПРОДАЖА СОПУТСТВУЮЩИХ ТОВАРОВ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724b1a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Anna/Desktop/ПРОЕКТ/ФАЙЛЫ_НАЦЕНКА\n"
     ]
    }
   ],
   "source": [
    "# Добавим кнопку выбора пути к папке\n",
    "def browse_button():\n",
    "    global path_sales\n",
    "    filename = filedialog.askdirectory()\n",
    "    path_sales.set(filename)\n",
    "    print(filename)\n",
    "root = Tk()\n",
    "path_sales = StringVar()\n",
    "lbl1 = Label(master=root,textvariable=path_sales)\n",
    "lbl1.grid(row=0, column=1)\n",
    "button2 = Button(text=\"Browse\", command=browse_button)\n",
    "button2.grid(row=0, column=3)\n",
    "\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4ef5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Anna/Desktop/ПРОЕКТ/ФАЙЛЫ_НАЦЕНКА\n"
     ]
    }
   ],
   "source": [
    "browse_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41df9fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Относительный путь к продажам - C:/Users/Anna/Desktop/ПРОЕКТ/ФАЙЛЫ_НАЦЕНКА\n"
     ]
    }
   ],
   "source": [
    "path_sales = input('Относительный путь к продажам - ')\n",
    "\n",
    "# путь\n",
    "p = Path(path_sales)\n",
    "\n",
    "# находим xlsx\n",
    "files = p.glob('*.xlsx')\n",
    "\n",
    "# df\n",
    "df_main = pd.concat([pd.read_excel(file, header=None, skiprows=2, skipfooter=1) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a74b3e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1640070, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41280441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чек/Возврат/Отчет\n",
      "удалено: 540726\n",
      "остаток строк: 1099344\n"
     ]
    }
   ],
   "source": [
    "# Делаем копию объединения файлов - для быстрого возврата к исходнику \n",
    "sales = df_main.copy()\n",
    "\n",
    "# Заполним отсутствующие данные по номеру чека, дате продажи и магазину предыдущими значениями\n",
    "sales[[3, 4, 5]] = sales[[3, 4, 5]].fillna(method = 'ffill')\n",
    "\n",
    "# Удалим строки, содержащие в столбце [0] возврат/чек/отчет и столбец с городом\n",
    "sales = sales[~sales[0].str.contains('Чек|Отчет|Возврат')]\n",
    "sales = sales.drop([2], axis=1)   \n",
    "sales.head()\n",
    "del1 = 1640070-sales[0].count()\n",
    "balance = sales[0].count()\n",
    "print('Чек/Возврат/Отчет')\n",
    "print(f'удалено: {del1}')\n",
    "print(f'остаток строк: {balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1081f016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дубликаты\n",
      "удалено: 384877\n",
      "остаток строк: 714467\n",
      "Составная часть\n",
      "удалено: -328655\n",
      "остаток строк: 713532\n",
      "Отсутствуют выручка и стоимость приобретения\n",
      "удалено: 15\n",
      "остаток строк: 713517\n"
     ]
    }
   ],
   "source": [
    "# В формате строки находится дата-время, преобразуем её в формат Timestamp и оставляем только дату\n",
    "sales[4] = pd.to_datetime(sales[4], format=\"%d.%m.%Y %H:%M:%S\").dt.date\n",
    "sales[4] = pd.to_datetime(sales[4])\n",
    "\n",
    "# Именуем колонки датафрейма\n",
    "sales.columns =  ['product', 'group_of_products', 'receipt', 'date', 'store', 'sold_quantity', \n",
    "                  'purchase_cost_VAT', 'tunover_VAT', 'margin_VAT']\n",
    "\n",
    "# Удаляем дубликаты \n",
    "sales = sales.drop_duplicates()\n",
    "del2 = balance-sales.store.count()\n",
    "balance = sales.store.count()\n",
    "print('Дубликаты')\n",
    "print(f'удалено: {del2}')\n",
    "print(f'остаток строк: {balance}')\n",
    "\n",
    "# Оставим в столбце store только наименование АЗС\n",
    "def text_clean(store): \n",
    "   store = re.findall(r'\\D{3}\\s+\\№\\s?\\d+', store)\n",
    "   return store\n",
    "sales.store = sales.store.apply(text_clean)\n",
    "sales.store = [' '.join(text) for text in sales.store]\n",
    "\n",
    "# Добавляем столбец city\n",
    "sales['city'] = np.nan\n",
    "\n",
    "# По АЗС №3 заполним город\n",
    "sales.city.loc[sales.store == 'АЗС №3'] = 'Севастополь г'\n",
    "sales.city.loc[sales.store == 'АЗС № 1'] = 'Симферополь г'\n",
    "sales.city.loc[sales.store == 'АЗС №2'] = 'Керчь г'\n",
    "sales.city.loc[sales.store == 'АЗС №4'] = 'Симферополь г'\n",
    "sales.city.loc[sales.store == 'АЗС №11'] = 'Симферополь г'\n",
    "\n",
    "# Удалим строки с группой \"Составная Часть\"\n",
    "sales = sales.loc[~(sales.group_of_products == 'Составная Часть')]\n",
    "del3 = del2-sales.store.count()\n",
    "balance = sales.store.count()\n",
    "print('Составная часть')\n",
    "print(f'удалено: {del3}')\n",
    "print(f'остаток строк: {balance}')\n",
    "\n",
    "\n",
    "# Удалим строки, в которых одновременно нет данных по выручке и приобретению\n",
    "sales = sales.loc[~((sales.purchase_cost_VAT.isna())&(sales.tunover_VAT.isna()))]\n",
    "del4 = balance-sales.store.count()\n",
    "balance = sales.store.count()\n",
    "print('Отсутствуют выручка и стоимость приобретения')\n",
    "print(f'удалено: {del4}')\n",
    "print(f'остаток строк: {balance}')\n",
    "\n",
    "# Заменим NaN в столбце tunover_VAT на 0\n",
    "sales.tunover_VAT = sales.tunover_VAT.fillna(0)\n",
    "sales.purchase_cost_VAT = sales.purchase_cost_VAT.fillna(0)\n",
    "                    \n",
    "# Рассчитаем значения столбцов\n",
    "sales['margin_VAT'] = sales.tunover_VAT - sales.purchase_cost_VAT\n",
    "sales['purchase_price_VAT'] = sales.purchase_cost_VAT / sales.sold_quantity\n",
    "sales['profit'] = sales.margin_VAT / sales.sold_quantity\n",
    "\n",
    "# Изменим порядок столбцов в датафрейме\n",
    "sales = sales[['date', 'receipt', 'product', 'group_of_products', 'store', 'city', 'sold_quantity', 'tunover_VAT',\n",
    "              'purchase_price_VAT', 'purchase_cost_VAT', 'margin_VAT', 'profit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a4a620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 713517 entries, 1 to 374482\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   date                713517 non-null  datetime64[ns]\n",
      " 1   receipt             713517 non-null  float64       \n",
      " 2   product             713517 non-null  object        \n",
      " 3   group_of_products   713517 non-null  object        \n",
      " 4   store               713517 non-null  object        \n",
      " 5   city                713517 non-null  object        \n",
      " 6   sold_quantity       713517 non-null  int64         \n",
      " 7   tunover_VAT         713517 non-null  float64       \n",
      " 8   purchase_price_VAT  713517 non-null  float64       \n",
      " 9   purchase_cost_VAT   713517 non-null  float64       \n",
      " 10  margin_VAT          713517 non-null  float64       \n",
      " 11  profit              713517 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(4)\n",
      "memory usage: 70.8+ MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f3698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно выгружен\n"
     ]
    }
   ],
   "source": [
    "# Создаем excel writer object \n",
    "out_path = 'C:/Users/Anna/Desktop/ПРОЕКТ/ФИНАЛ/sales_final.xlsx'\n",
    "writer = pd.ExcelWriter(out_path , engine='xlsxwriter') \n",
    "# Записываем датафрейм в excel \n",
    "sales.to_excel(writer) \n",
    "# Сохраняем файл excel \n",
    "writer.save() \n",
    "print('Файл успешно выгружен')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59399de9",
   "metadata": {},
   "source": [
    "### **ПРОДАЖА ТОПЛИВА**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354a8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Относительный путь к продажам - C:/Users/Anna/Desktop/ПРОЕКТ/ФАЙЛЫ_ТОПЛИВО\n"
     ]
    }
   ],
   "source": [
    "path_oil = input('Относительный путь к продажам - ')\n",
    "\n",
    "# путь\n",
    "o = Path(path_oil)\n",
    "\n",
    "# находим xlsx\n",
    "files_oil = o.glob('*.xlsx')\n",
    "\n",
    "# df\n",
    "df_oil = pd.concat([pd.read_excel(file, header=None, skiprows=6, skipfooter=1) for file in files_oil])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ca734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>date</th>\n",
       "      <th>receipt</th>\n",
       "      <th>oil_product</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АЗС № 1</td>\n",
       "      <td>20.09.2017 22:44:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>АИ-95-К5</td>\n",
       "      <td>2.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>АЗС № 1</td>\n",
       "      <td>20.09.2017 22:51:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>АИ-95-К5</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>АЗС № 1</td>\n",
       "      <td>20.09.2017 23:05:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>АИ-95-К5</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>АЗС № 1</td>\n",
       "      <td>20.09.2017 23:21:16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>АИ-95-К5</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>АЗС № 1</td>\n",
       "      <td>20.09.2017 23:21:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>АИ-95-К5</td>\n",
       "      <td>2.824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     store                 date  receipt oil_product  quantity\n",
       "0  АЗС № 1  20.09.2017 22:44:46      1.0    АИ-95-К5     2.353\n",
       "1  АЗС № 1  20.09.2017 22:51:52      1.0    АИ-95-К5     2.000\n",
       "2  АЗС № 1  20.09.2017 23:05:57      1.0    АИ-95-К5     2.000\n",
       "3  АЗС № 1  20.09.2017 23:21:16      1.0    АИ-95-К5     2.000\n",
       "4  АЗС № 1  20.09.2017 23:21:26      1.0    АИ-95-К5     2.824"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Делаем копию объединения файлов - для быстрого возврата к исходнику \n",
    "oil_sales = df_oil\n",
    "\n",
    "# Заполняем отсутствующие номера чеков \"1\"\n",
    "oil_sales[2] = oil_sales[2].fillna(1)\n",
    "\n",
    "# Именуем колонки датафрейма\n",
    "oil_sales.columns =  ['store', 'date', 'receipt', 'oil_product', 'quantity']\n",
    "\n",
    "# Оставим в столбце store только наименование АЗС\n",
    "def text_clean(store): \n",
    "   store = re.findall(r'\\D{3}\\s+\\№\\s?\\d+', store)\n",
    "   return store\n",
    "oil_sales.store = oil_sales.store.apply(text_clean)\n",
    "oil_sales.store = [' '.join(text) for text in oil_sales.store]\n",
    "\n",
    "oil_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c57ba175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1604666 entries, 0 to 373844\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   store        1604666 non-null  object \n",
      " 1   date         1604665 non-null  object \n",
      " 2   receipt      1604666 non-null  float64\n",
      " 3   oil_product  1604666 non-null  object \n",
      " 4   quantity     1604666 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 73.5+ MB\n"
     ]
    }
   ],
   "source": [
    "oil_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e470a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно выгружен\n"
     ]
    }
   ],
   "source": [
    "# Создаем excel writer object \n",
    "out_path = 'C:/Users/Anna/Desktop/ПРОЕКТ/ФИНАЛ/oil_sales.xlsx'\n",
    "writer = pd.ExcelWriter(out_path , engine='xlsxwriter') \n",
    "# Записываем датафрейм в excel \n",
    "sales.to_excel(writer) \n",
    "# Сохраняем файл excel \n",
    "writer.save() \n",
    "print('Файл успешно выгружен')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71797e4",
   "metadata": {},
   "source": [
    "### **ПОГОДА**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b00170f",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 401: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5740/874359722.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Скачаем данные по погоде в городах: Симферополь, Севастополь, Керчь\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msimferopol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/simferopol/2017-01-01/2022-09-30?unitGroup=metric&include=days&key=NL2GLB33XY6PTWA6MH4J2HF97&contentType=csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'temp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'precip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cloudcover'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'icon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msevastopol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/sevastopol/2017-01-01/2022-09-30?unitGroup=metric&include=days&key=NL2GLB33XY6PTWA6MH4J2HF97&contentType=csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'temp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'precip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cloudcover'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'icon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mkerch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/kerch/2017-01-01/2022-09-30?unitGroup=metric&include=days&key=NL2GLB33XY6PTWA6MH4J2HF97&contentType=csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'temp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'precip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cloudcover'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'icon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[1;31m# open URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    633\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANAKONDA\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 401: "
     ]
    }
   ],
   "source": [
    "# Авторизуемся на сайте архива погоды\n",
    "s = requests.Session()\n",
    "data = {\"login_username\":\"kav2005@bk.ru\", \"login_password\":\"19772004\"}\n",
    "url = \"https://www.visualcrossing.com/account\"\n",
    "\n",
    "# Скачаем данные по погоде в городах: Симферополь, Севастополь, Керчь\n",
    "with requests.Session() as s:\n",
    "    simferopol = pd.read_csv('https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/simferopol/2017-01-01/2022-09-30?unitGroup=metric&include=days&key=NL2GLB33XY6PTWA6MH4J2HF97&contentType=csv',usecols = ['name', 'datetime', 'temp', 'precip', 'cloudcover', 'icon'])\n",
    "    sevastopol = pd.read_csv('https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/sevastopol/2017-01-01/2022-09-30?unitGroup=metric&include=days&key=NL2GLB33XY6PTWA6MH4J2HF97&contentType=csv',usecols = ['name', 'datetime', 'temp', 'precip', 'cloudcover', 'icon'])\n",
    "    kerch = pd.read_csv('https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/kerch/2017-01-01/2022-09-30?unitGroup=metric&include=days&key=NL2GLB33XY6PTWA6MH4J2HF97&contentType=csv',usecols = ['name', 'datetime', 'temp', 'precip', 'cloudcover', 'icon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменим названия городов\n",
    "simferopol['name'] = 'Симферополь г'\n",
    "sevastopol['name'] = 'Севастополь г'\n",
    "kerch['name'] = 'Керчь г'\n",
    "\n",
    "# Соединим три датафрейма в один\n",
    "weather = pd.concat((simferopol, sevastopol, kerch), axis=0)\n",
    "\n",
    "# Переименуем столбцы datetime и name\n",
    "weather.rename(columns={'name': 'city', 'datetime': 'date'}, inplace=True)\n",
    "\n",
    "# Переведем столбец 'datetime' в тип данных datetime\n",
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42708dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на уникальные значения в колонке 'icon'\n",
    "print(weather['icon'].unique())\n",
    "\n",
    "# Заменим описание погоды на русскоязычные значения\n",
    "weather.icon.loc[(weather.icon == 'rain')] = 'Дождь'\n",
    "weather.icon.loc[(weather.icon == 'clear-day')] = 'Ясно'\n",
    "weather.icon.loc[(weather.icon == 'partly-cloudy-day')] = 'Переменная облачность'\n",
    "weather.icon.loc[(weather.icon == 'snow')] = 'Снег'\n",
    "weather.icon.loc[(weather.icon == 'cloudy')] = 'Облачно'\n",
    "weather.icon.loc[(weather.icon == 'wind')] = 'Ветрено'\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87226102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем excel writer object \n",
    "out_path = 'C:/Users/Anna/Desktop/ПРОЕКТ/ФИНАЛ/weather.xlsx'\n",
    "writer = pd.ExcelWriter(out_path , engine='xlsxwriter') \n",
    "# Записываем датафрейм в excel \n",
    "sales.to_excel(writer) \n",
    "# Сохраняем файл excel \n",
    "writer.save() \n",
    "print('Файл успешно выгружен')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
